
====================================================================================================
PERFORMANCE METRICS TABLE
====================================================================================================

Model                          |    ROUGE-1 |    ROUGE-2 |    ROUGE-L |       BLEU |     METEOR
----------------------------------------------------------------------------------------------------
Baseline (No Fine-tuning)      |     0.2111 |     0.0987 |     0.1473 |     0.0435 |     0.3464
Fine-tuned (checkpoint-4)      |     0.2111 |     0.0987 |     0.1473 |     0.0435 |     0.3464
====================================================================================================

====================================================================================================
IMPROVEMENT ANALYSIS
====================================================================================================

Fine-tuned Model vs Baseline:
  • ROUGE-1 Improvement: +0.00%
  • ROUGE-2 Improvement: +0.00%
  • ROUGE-L Improvement: +0.00%
  • BLEU Improvement:    +0.00%
  • METEOR Improvement:  +0.00%


====================================================================================================
BIAS DETECTION METRICS
====================================================================================================

Metric                         |        Baseline |      Fine-tuned
----------------------------------------------------------------------
Avg Sentiment Polarity         |          0.0890 |          0.0890
Avg Subjectivity               |          0.4200 |          0.4200
Avg Bias Score                 |          0.2000 |          0.2000
% Subjective Summaries         |          20.00% |          20.00%


====================================================================================================
MARKDOWN FORMAT (Copy to your report)
====================================================================================================

| Model | ROUGE-1 | ROUGE-2 | ROUGE-L | BLEU | METEOR |
|-------|---------|---------|---------|------|--------|
| Baseline (No Fine-tuning) | 0.2111 | 0.0987 | 0.1473 | 0.0435 | 0.3464 |
| Fine-tuned (checkpoint-4) | 0.2111 | 0.0987 | 0.1473 | 0.0435 | 0.3464 |


====================================================================================================
LATEX FORMAT (For academic papers)
====================================================================================================

\begin{table}[h]
\centering
\caption{Performance Comparison of Models}
\begin{tabular}{|l|c|c|c|c|c|}
\hline
\textbf{Model} & \textbf{ROUGE-1} & \textbf{ROUGE-2} & \textbf{ROUGE-L} & \textbf{BLEU} & \textbf{METEOR} \\
\hline
Baseline (No Fine-tuning) & 0.2111 & 0.0987 & 0.1473 & 0.0435 & 0.3464 \\
Fine-tuned (checkpoint-4) & 0.2111 & 0.0987 & 0.1473 & 0.0435 & 0.3464 \\
\hline
\end{tabular}
\end{table}


====================================================================================================
EXAMPLE PREDICTIONS (First 3)
====================================================================================================
